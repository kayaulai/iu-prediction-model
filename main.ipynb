{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# set the random seed for reproduction\n",
    "SEED=190\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#checking if GPU is available or not\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('predict_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class SBCDataset(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "    def __len__(self):\n",
    "    \n",
    "    def __getitem__(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 1024\n",
    "\n",
    "# create the dataset\n",
    "train_ds = SBCDataset(train_df)\n",
    "valid_ds = SBCDataset(valid_df)\n",
    "\n",
    "# build the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=TEST_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "        A learning pipeline to train and validate the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, criterion, optimizer, max_epoch):\n",
    "        \"\"\"\n",
    "            model: nn model\n",
    "            criterion: loss function\n",
    "            optimizer: optimizer\n",
    "            max_epoch: maximum training epoch\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.max_epoch = max_epoch\n",
    "        \n",
    "    def run(self,train_loader, valid_loader):\n",
    "        \"\"\"\n",
    "            Main entry\n",
    "                train_loader: training dataset, each item is (img, label)\n",
    "                valid_loader: validation dataset, each item is (img, label)\n",
    "        \"\"\"\n",
    "        # calculate the inital loss and accu on validation set\n",
    "        valid_best_loss = self.validate(-1, valid_loader, best_loss=None)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            self.train(epoch, train_loader)\n",
    "            # save the checkpoint with the lowest validation loss\n",
    "            valid_best_loss = self.validate(epoch, valid_loader, valid_best_loss)\n",
    "        \n",
    "    def train(self, epoch, loader):\n",
    "        \"\"\"\n",
    "            Single training loop\n",
    "                epoch: int, current epoch index\n",
    "                loader: training loader\n",
    "        \"\"\"\n",
    "        # switch to the train mode, calculate the gradient\n",
    "        self.model.train()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        with tqdm(enumerate(loader, 0), mininterval=10) as tepoch:\n",
    "            for i, data in tepoch:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                # inputs: tensor, (batch_size, image_size, image_size)\n",
    "                # labels: tensor, (batch_size, 1)\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs,labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # calculate the metric\n",
    "                match, number = self.cal_metric(outputs.data, labels)\n",
    "                \n",
    "                # gather statistics\n",
    "                total += number\n",
    "                correct += match\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * correct / total)\n",
    "\n",
    "        running_loss /= len(loader)\n",
    "\n",
    "        print('Training | Epoch: {}| Loss: {:.3f} | Accuracy on train images: {:.1f}'.format \\\n",
    "              (epoch+1, running_loss, 100 * correct / total))\n",
    "        \n",
    "    def validate(self, epoch, loader, best_loss=None):\n",
    "        \"\"\"\n",
    "            Single evaluation loop\n",
    "                epoch: int, current epoch index\n",
    "                loader: validation loader\n",
    "                best_loss: float, current best loss\n",
    "        \"\"\"\n",
    "        # switch to the evaluation mode, do not need to calculate the gradient\n",
    "        self.model.eval()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        for i, data in tqdm(enumerate(loader)):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs,labels)\n",
    "\n",
    "            match, number = self.cal_metric(outputs.data, labels)\n",
    "            \n",
    "            total += number\n",
    "            correct += match\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(loader)\n",
    "\n",
    "        if best_loss is None or running_loss < best_loss:\n",
    "            # if a better loss appears, save the checkpoint\n",
    "            save_file = 'best_epoch{}_loss{:.2f}_accu{:.2f}.pt'.format(epoch+1, running_loss, 100 * correct / total)\n",
    "            print('Save to file: ', save_file)\n",
    "            torch.save(self.model, save_file)\n",
    "            \n",
    "            # overwrite the best_checkpoint.pt file\n",
    "            torch.save(self.model, 'best_checkpoint.pt')\n",
    "            \n",
    "            best_loss = running_loss\n",
    "\n",
    "        print('Validation | Epoch: {}| Loss: {:.3f} | Accuracy on val images: {:.1f}'.format \\\n",
    "              (epoch+1, running_loss,100 * correct / total))\n",
    "\n",
    "        return best_loss\n",
    "\n",
    "                \n",
    "    def cal_metric(self, outputs, labels):\n",
    "        \"\"\"\n",
    "            Calculate the accuracy\n",
    "                outputs: tensor (batch_size, number_class), the output of the model\n",
    "                labels: tensor (batch_size, 1), the ground truth\n",
    "        \"\"\"\n",
    "        # compare predictions to ground truth\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        number = labels.size(0)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        return correct, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "        Multilayer perceptron network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(1024, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.layers(x)\n",
    "        # F.log_softmax returns the log probabilities of each class\n",
    "        # of shape (num_samples, num_classes)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "NUM_EPOCH = 20\n",
    "LEARNING_RATE = 0.001\n",
    "model = MLP()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "trainer = Trainer(model, criterion, optimizer, max_epoch=NUM_EPOCH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
