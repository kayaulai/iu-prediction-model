{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# set the random seed for reproduction\n",
    "SEED=190\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#checking if GPU is available or not\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split into Train and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(df):\n",
    "    data_category = {}\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[[col]][0] == object:\n",
    "            data_category[col] = {}\n",
    "            for (i, cat) in enumerate(df[[col]].drop_duplicates().values.flatten().tolist()):\n",
    "                data_category[col][cat] = i\n",
    "    \n",
    "    return data_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predict_df.csv', low_memory=False)\n",
    "data_category = get_category(df)\n",
    "\n",
    "msk = np.random.rand(len(df)) > 0.2\n",
    "train_df = df[msk]\n",
    "valid_df = df[~msk]\n",
    "# train_df.to_csv('sbc_train.csv', index=False)\n",
    "# valid_df.to_csv('sbc_valid.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class SBCDataset(Dataset):\n",
    "    def __init__(self, raw_data, cat_dict: dict, predictors: List[str], response: str, inference=False):\n",
    "        self.cat_dict = cat_dict\n",
    "        self.pred_data = self.one_hot(raw_data, cat_dict, predictors)\n",
    "        self.labels = raw_data[[response]].to_numpy(dtype=float)\n",
    "        self.inference = inference\n",
    "        self.shape = self.pred_data.shape\n",
    "\n",
    "    def one_hot(self, raw_data, cat_dict, predictors):\n",
    "        data = np.zeros(shape=(len(raw_data), 1))\n",
    "        for col in predictors:\n",
    "            if \"currLength\" not in col and \":\" not in col:\n",
    "                data = np.append(data, \n",
    "                                raw_data[[col]].replace(cat_dict).to_numpy(), \n",
    "                                axis=1)\n",
    "            elif \":\" in col:\n",
    "                temp_col = col.split(\":\")\n",
    "                data = np.append(data, \n",
    "                                raw_data[[temp_col[0]]].replace(cat_dict).to_numpy() * raw_data[[temp_col[1]]].to_numpy(), \n",
    "                                axis=1)\n",
    "            else: \n",
    "                data = np.append(data, raw_data[[col]].to_numpy(dtype=float), axis=1)\n",
    "        return data[:, 1:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pred_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.inference:\n",
    "            label = self.labels[idx]\n",
    "            return torch.tensor(self.pred_data[idx], dtype=torch.float), torch.tensor(label, dtype=torch.float)\n",
    "        else:\n",
    "            return torch.tensor(self.pred_data[idx], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2048\n",
    "TEST_BATCH_SIZE = 2048\n",
    "\n",
    "# create the dataset\n",
    "predictors = [\"prevEndnote\", \"prev1\", \"prev2\", \"prev3\", \"currLength\", \"init1\", \"init2\", \"init3\"]\n",
    "train_ds = SBCDataset(train_df, cat_dict=data_category, predictors=predictors, response=\"preBoundary\")\n",
    "valid_ds = SBCDataset(valid_df, cat_dict=data_category, predictors=predictors, response=\"preBoundary\")\n",
    "\n",
    "# build the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=TEST_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Training and Validation Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, criterion, lr_rate, max_epoch):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr_rate)\n",
    "        self.max_epoch = max_epoch\n",
    "\n",
    "    def run(self, train_loader, valid_loader):\n",
    "        # calculate the inital loss and accu on validation set\n",
    "        valid_best_loss = self.validate(-1, valid_loader, best_loss=None)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            self.train(epoch, train_loader)\n",
    "            # save the checkpoint with the lowest validation loss\n",
    "            valid_best_loss = self.validate(epoch, valid_loader, valid_best_loss)\n",
    "\n",
    "    def train(self, epoch, loader):            \n",
    "        self.model.train()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        with tqdm(enumerate(loader, 0), mininterval=10) as tepoch:\n",
    "            for i, data in tepoch:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                # inputs: tensor, (batch_size, predictors_size)\n",
    "                # labels: tensor, (batch_size, 1)\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # calculate the metric\n",
    "                match, number = self.cal_metric(outputs.data, labels)\n",
    "\n",
    "                # gather statistics\n",
    "                total += number\n",
    "                correct += match\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * correct / total)\n",
    "\n",
    "        running_loss /= len(loader)\n",
    "        \n",
    "        print('Training | Epoch: {}| Loss: {:.3f} | Accuracy on train: {:.1f}%'.format \\\n",
    "              (epoch+1, running_loss, 100 * correct / total))\n",
    "\n",
    "    def validate(self, epoch, loader, best_loss=None):\n",
    "        # switch to the evaluation mode, do not need to calculate the gradient\n",
    "        self.model.eval()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        for i, data in tqdm(enumerate(loader)):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # replace the outputs and loss\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "\n",
    "            # calculate the metric\n",
    "            match, number = self.cal_metric(outputs.data, labels)\n",
    "\n",
    "            # gather statistics\n",
    "            total += number\n",
    "            correct += match\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(loader)\n",
    "\n",
    "        if best_loss is None or running_loss < best_loss:\n",
    "            # if a better loss appears, save the checkpoint\n",
    "            save_file = 'best_epoch{}_loss{:.2f}_accu{:.2f}.pt'.format(epoch+1, running_loss, 100 * correct / total)\n",
    "            print('Save to file: ', save_file)\n",
    "            torch.save(self.model, save_file)\n",
    "\n",
    "            # overwrite the best_checkpoint.pt file\n",
    "            torch.save(self.model, 'best_checkpoint.pt')\n",
    "\n",
    "            best_loss = running_loss\n",
    "\n",
    "        print('Validation | Epoch: {}| Loss: {:.3f} | Accuracy on val: {:.1f}%'.format \\\n",
    "              (epoch+1, running_loss,100 * correct / total))\n",
    "\n",
    "        return best_loss\n",
    "\n",
    "\n",
    "    def cal_metric(self, outputs, labels):\n",
    "        # compare predictions to ground truth\n",
    "        _, predicted = torch.max(outputs, 1, keepdim=True)\n",
    "        number = labels.size(0)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        return correct, number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define the Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 20\n",
    "LEARNING_RATE = 0.001\n",
    "input_shape = train_ds.shape\n",
    "model = MLP(input_shape[-1])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "trainer = Trainer(model, criterion, LEARNING_RATE, max_epoch=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 60.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to file:  best_epoch0_loss24.48_accu75.51.pt\n",
      "Validation | Epoch: 0| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 47.47it/s, accuracy=75.7, loss=22.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 1| Loss: 24.301 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 66.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 1| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:01, 51.93it/s, accuracy=75.7, loss=24.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 2| Loss: 24.307 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 59.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 2| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 36.09it/s, accuracy=75.7, loss=23.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 3| Loss: 24.304 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 31.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 3| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 41.03it/s, accuracy=75.7, loss=23.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 4| Loss: 24.304 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 29.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 4| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:03, 27.52it/s, accuracy=75.7, loss=23.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 5| Loss: 24.304 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 5| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 34.86it/s, accuracy=75.7, loss=26.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 6| Loss: 24.311 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:01, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 6| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:04, 23.46it/s, accuracy=75.7, loss=23.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 7| Loss: 24.303 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 50.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 7| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:03, 34.23it/s, accuracy=75.7, loss=23.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 8| Loss: 24.304 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 48.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 8| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:03, 26.84it/s, accuracy=75.7, loss=24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 9| Loss: 24.305 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 37.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 9| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 36.09it/s, accuracy=75.7, loss=23.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 10| Loss: 24.303 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 56.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 10| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:03, 31.96it/s, accuracy=75.7, loss=26.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 11| Loss: 24.312 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 56.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 11| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 37.27it/s, accuracy=75.7, loss=27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 12| Loss: 24.312 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 48.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 12| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 38.78it/s, accuracy=75.7, loss=22.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 13| Loss: 24.302 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 50.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 13| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 35.27it/s, accuracy=75.7, loss=24.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 14| Loss: 24.306 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 44.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 14| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:03, 31.28it/s, accuracy=75.7, loss=25.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 15| Loss: 24.308 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 56.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 15| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 40.36it/s, accuracy=75.7, loss=24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 16| Loss: 24.305 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 42.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 16| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 42.71it/s, accuracy=75.7, loss=24.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 17| Loss: 24.306 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 44.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 17| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 45.08it/s, accuracy=75.7, loss=23.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 18| Loss: 24.305 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 59.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 18| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:03, 32.84it/s, accuracy=75.7, loss=24.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 19| Loss: 24.306 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 19| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:02, 44.24it/s, accuracy=75.7, loss=25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training | Epoch: 20| Loss: 24.308 | Accuracy on train: 75.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:00, 52.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation | Epoch: 20| Loss: 24.485 | Accuracy on val: 75.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.run(train_loader, valid_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
